{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('NaN')\n",
    "df_test = df_test.fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_countries = df.groupby(['Date', 'Country_Region'], as_index=False)\\\n",
    "                    .agg({'ConfirmedCases': 'sum', 'Fatalities': 'sum'})\n",
    "\n",
    "dates_countries['Date'] = pd.to_datetime(dates_countries['Date'])\n",
    "training_mask = np.logical_and(pd.to_datetime('2020-01-19') < dates_countries['Date'],\n",
    "                               dates_countries['Date'] < pd.to_datetime('2020-03-19'))\n",
    "data = dates_countries[training_mask].copy()\n",
    "data.loc[:, ('ConfirmedCases', 'Fatalities')] = data.loc[:, ['ConfirmedCases', 'Fatalities']] \\\n",
    "                                                .apply(lambda x: np.log1p(x))\n",
    "data.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, ('ConfirmedCases', 'Fatalities')] = data.loc[:, ['ConfirmedCases', 'Fatalities']] \\\n",
    "                                                .apply(lambda x: np.log1p(x))\n",
    "data.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagging(df, lags=10):\n",
    "    dfs = []\n",
    "    for i in range(1, lags):\n",
    "        lag_df = df.shift(i, fill_value=0)\n",
    "        lag_df = lag_df.rename(lambda x: x + f'_{i}', axis=1)\n",
    "        dfs.append(lag_df)\n",
    "    \n",
    "    return pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data['Day_num'] = le.fit_transform(data.Date)\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['Month'] = data['Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dfs = []\n",
    "for country in ['Italy']:#dates_countries['Country_Region'].unique():\n",
    "    country_mask = data['Country_Region'] == country\n",
    "    country_df = data.loc[country_mask]\n",
    "    lags_df = lagging(country_df[['ConfirmedCases', 'Fatalities']])\n",
    "    country_df = pd.concat([country_df, lags_df], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Brute-force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_train_test_split(X, y, test_size):\n",
    "    \"\"\"\n",
    "        Perform train-test split with respect to time series structure\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the index after which test set starts\n",
    "    test_index = int(len(X)*(1-test_size))\n",
    "    \n",
    "    X_train = X.iloc[:test_index]\n",
    "    y_train = y.iloc[:test_index]\n",
    "    X_test = X.iloc[test_index:]\n",
    "    y_test = y.iloc[test_index:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def timeseriesCVscore(model, X, y, n_splits, loss_function):\n",
    "    \"\"\"\n",
    "        Returns error on CV  \n",
    "        \n",
    "        params - vector of parameters for optimization\n",
    "        series - dataset with timeseries\n",
    "        slen - season length for Holt-Winters model\n",
    "    \"\"\"\n",
    "    # errors array\n",
    "    errors = []\n",
    "\n",
    "    \n",
    "    # set the number of folds for cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits) \n",
    "    \n",
    "    # iterating over folds, train model on each, forecast and calculate error\n",
    "    for train, test in tscv.split(X, y):\n",
    "        start_time = time.time()\n",
    "        model = model.fit(X[train], y[train])\n",
    "        fit_time = time.time() - start_time\n",
    "        \n",
    "        y_pred = model.predict(X[test])\n",
    "        y_true = y[test]\n",
    "        error = loss_function(y_pred, y_true)\n",
    "        score_time = time.time() - start_time - fit_time\n",
    "        errors.append(error)\n",
    "        \n",
    "        cv_results['train_score'].append()\n",
    "        cv_results['test_score'].append(error)\n",
    "    \n",
    "    res\n",
    "    return np.mean(np.array(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss, hinge_loss, f1_score, precision_score\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.expm1(x))\n",
    "# data_pred.replace([np.inf, -np.inf], 0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_confirmed = country_df['ConfirmedCases'].to_numpy()\n",
    "y_fatalities = country_df['Fatalities'].to_numpy()\n",
    "X_train = country_df.drop(columns=['Date', 'Country_Region', 'ConfirmedCases', 'Fatalities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_confirmed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ML_methods = [\n",
    "    ensemble.AdaBoostRegressor(),\n",
    "    ensemble.BaggingRegressor(),\n",
    "    ensemble.ExtraTreesRegressor(),\n",
    "    ensemble.RandomForestRegressor(),\n",
    "    ensemble.GradientBoostingRegressor(),\n",
    "    ensemble.RandomForestRegressor(),\n",
    "#     linear_model.LogisticRegression(),\n",
    "    linear_model.PassiveAggressiveRegressor(),\n",
    "    linear_model.Ridge(),\n",
    "#     linear_model.SGDRegressor(),\n",
    "#     linear_model.Perceptron(),\n",
    "#     naive_bayes.BernoulliNB(),\n",
    "#     naive_bayes.GaussianNB(),\n",
    "    neighbors.KNeighborsRegressor(),\n",
    "    svm.SVR(),\n",
    "    svm.NuSVR(),\n",
    "    svm.LinearSVR(),\n",
    "#     discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "#     discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "    ]\n",
    "\n",
    "ML_columns = ['ML Name', 'ML Parameters','ML Train Error Mean', 'ML Test Error Mean', 'ML Test Error 3*STD' ,'ML Time']\n",
    "ML_compare = pd.DataFrame(columns = ML_columns)\n",
    "ML_predict = {}\n",
    "# rmsle = metrics.mean_squared_log_error\n",
    "tscv = TimeSeriesSplit(n_splits=3) \n",
    "\n",
    "for row_index, clf in tqdm(enumerate(ML_methods)):\n",
    "    print(f'Training: {clf.__class__.__name__}')\n",
    "    cv_results = model_selection.cross_validate(clf, X_train, y_confirmed, cv=tscv, scoring='neg_mean_squared_error')\n",
    "\n",
    "    ML_name = clf.__class__.__name__\n",
    "    ML_compare.loc[row_index, 'ML Name'] = ML_name\n",
    "    ML_compare.loc[row_index, 'ML Parameters'] = str(clf.get_params())\n",
    "    ML_compare.loc[row_index, 'ML Time'] = cv_results['fit_time'].mean()\n",
    "#     ML_compare.loc[row_index, 'ML Train Error Mean'] = -1 * cv_results['train_score'].mean()\n",
    "    ML_compare.loc[row_index, 'ML Test Error Mean'] = -1 * cv_results['test_score'].mean()   \n",
    "    ML_compare.loc[row_index, 'ML Test Error 3*STD'] = 3 * cv_results['test_score'].std()\n",
    "\n",
    "    clf = clf.fit(X_train, y_confirmed)\n",
    "    ML_predict[ML_name] = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_compare.sort_values(by = ['ML Test Error Mean'], ascending = True, inplace = True)\n",
    "ML_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "sns.barplot(x='ML Test Error Mean', y = 'ML Name', data = ML_compare, color = 'm')\n",
    "plt.title('Machine Learning Algorithms Score \\n')\n",
    "plt.xlabel('RMSLE Score')\n",
    "plt.ylabel('Algorithm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
