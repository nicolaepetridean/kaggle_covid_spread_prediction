{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv').fillna('NaN').drop(columns=['Id'])\n",
    "test_data = pd.read_csv('test.csv').fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_training = pd.to_datetime('2020-01-19')\n",
    "train_up_to = pd.to_datetime('2020-03-25')\n",
    "public_test_up_to = pd.to_datetime('2020-04-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Date'] = pd.to_datetime(train_data['Date'])\n",
    "test_data['Date'] = pd.to_datetime(test_data['Date'])\n",
    "\n",
    "public_mask = np.logical_and(start_training < train_data['Date'], train_data['Date'] <= train_up_to)\n",
    "\n",
    "train_data = train_data[public_mask].copy()\n",
    "train_data.loc[:, ('ConfirmedCases', 'Fatalities')] = train_data.loc[:, ['ConfirmedCases', 'Fatalities']] \\\n",
    "                                                      .apply(lambda x: np.log1p(x), )\n",
    "train_data.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['ForecastId'] = -1\n",
    "\n",
    "test_data['ConfirmedCases'] = 0.0\n",
    "test_data['Fatalities'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagging(df, lags=10):\n",
    "    dfs = []\n",
    "    for i in range(1, lags):\n",
    "        lag_df = df.shift(i, fill_value=0)\n",
    "        lag_df = lag_df.rename(lambda x: x + f'_{i}', axis=1)\n",
    "        dfs.append(lag_df)\n",
    "    \n",
    "    return pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "train_mask = data['ForecastId'] == -1\n",
    "test_mask = ~train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(data):\n",
    "    le = LabelEncoder()\n",
    "    data['Day_num'] = le.fit_transform(data.Date)\n",
    "    data['Day'] = data['Date'].dt.day\n",
    "    data['Month'] = data['Date'].dt.month\n",
    "    return data\n",
    "\n",
    "data = add_time_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[train_mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[test_mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Brute-force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss, hinge_loss, f1_score, precision_score\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.expm1(x))\n",
    "# data_pred.replace([np.inf, -np.inf], 0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_models(X_train, y_confirmed):\n",
    "    ML_methods = [\n",
    "        ensemble.AdaBoostRegressor(),\n",
    "        ensemble.BaggingRegressor(),\n",
    "        ensemble.ExtraTreesRegressor(),\n",
    "        ensemble.RandomForestRegressor(),\n",
    "        ensemble.GradientBoostingRegressor(),\n",
    "        ensemble.RandomForestRegressor(),\n",
    "        linear_model.PassiveAggressiveRegressor(),\n",
    "        linear_model.Ridge(),\n",
    "        neighbors.KNeighborsRegressor(),\n",
    "        svm.SVR(),\n",
    "        svm.NuSVR(),\n",
    "        svm.LinearSVR(),\n",
    "    ]\n",
    "\n",
    "    ML_columns = ['ML Name', 'ML Parameters', 'ML Test Error Mean', 'ML Test Error 3*STD' ,'ML Time']\n",
    "    ML_compare = pd.DataFrame(columns = ML_columns)\n",
    "    ML_predict = {}\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=3) \n",
    "    for row_index, clf in enumerate(ML_methods):\n",
    "\n",
    "        cv_results = model_selection.cross_validate(clf, X_train, y_confirmed, cv=tscv, scoring='neg_mean_squared_error')\n",
    "\n",
    "        ML_name = clf.__class__.__name__\n",
    "        ML_compare.loc[row_index, 'ML Name'] = ML_name\n",
    "        ML_compare.loc[row_index, 'ML Parameters'] = str(clf.get_params())\n",
    "        ML_compare.loc[row_index, 'ML Time'] = cv_results['fit_time'].mean()\n",
    "        ML_compare.loc[row_index, 'ML Test Error Mean'] = -1 * cv_results['test_score'].mean()   \n",
    "        ML_compare.loc[row_index, 'ML Test Error 3*STD'] = 3 * cv_results['test_score'].std()\n",
    "\n",
    "        clf = clf.fit(X_train, y_confirmed)\n",
    "        ML_predict[ML_name] = np.expm1(clf.predict(X_train))\n",
    "    return ML_compare, ML_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_df):\n",
    "    confirmed_queue = deque(test_df_reduced.loc[:10, 'ConfirmedCases'], maxlen=10)\n",
    "    fatalities_queue = deque(test_df_reduced.loc[:10, 'Fatalities'], maxlen=10)\n",
    "\n",
    "    res = []\n",
    "    for i, df_row in test_df.iterrows():\n",
    "        X_test = df_row['Day_num', 'Day', 'Month'].to_numpy().tolist()\n",
    "        confirmed_pred = model.predict([X_test + list(confirmed_queue)])\n",
    "        fatalities_pred = model.predict([X_test + list(fatalities_queue)])\n",
    "        confirmed_queue.append(confirmed_pred)\n",
    "        fatalities_queue.append(fatalities_pred)\n",
    "\n",
    "        test_df.loc[i, 'ConfirmedCases'] = confirmed_pred\n",
    "        test_df.loc[i, 'Fatalities'] = fatalities_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcolumns_to_drop = ['Date', 'Country_Region', 'Province_State', 'ConfirmedCases', 'Fatalities']\n",
    "\n",
    "country_dfs = []\n",
    "for country in tqdm(data['Country_Region'].unique()):\n",
    "    country_df = data.loc[data['Country_Region'] == country]\n",
    "    for state in country_df['Province_State'].unique():\n",
    "        curr_state_mask = np.logical_and(data['Country_Region'] == country, data['Province_State'] == state)\n",
    "        curr_state_data = data[curr_state_mask].copy()\n",
    "\n",
    "        lags_data = lagging(curr_state_data[['ConfirmedCases', 'Fatalities']])\n",
    "        data_with_lags = pd.concat([curr_state_data, lags_data], axis=1).dropna()\n",
    "        state_train_mask = data_with_lags['ForecastId'] == -1\n",
    "        \n",
    "        state_train_data = data_with_lags[state_train_mask]\n",
    "        state_test_data = data_with_lags[~state_train_mask]\n",
    "        \n",
    "        y_confirmed = state_train_data['ConfirmedCases'].to_numpy()\n",
    "        y_fatalities = state_train_data['Fatalities'].to_numpy()\n",
    "        X_train = state_train_data.drop(columns=columns_to_drop + ['ForecastId'])\n",
    "        print(X_train.columns)\n",
    "        predict(None, state_test_data)\n",
    "        models_df, models_res = train_models(X_train, y_confirmed)\n",
    "        models_df['country'] = country\n",
    "        models_df['state'] = state\n",
    "        country_dfs.append(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jtplot submodule from jupyterthemes\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "# currently installed theme will be used to\n",
    "# set plot style if no arguments provided\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for country in tqdm(train_data['Country_Region'].unique()):\n",
    "    country_df = train_data.loc[train_data['Country_Region'] == country]\n",
    "    for state in country_df['Province_State'].unique():\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        sns.barplot(x='ML Test Error Mean', y = 'ML Name', data = country_dfs[i], color = 'm')\n",
    "        plt.title(country + ':' + state + ' ' + str(i))\n",
    "        plt.xlabel('RMSLE Score')\n",
    "        plt.ylabel('Algorithm')\n",
    "        plt.show()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg_basic_all_countries(data, day_start):\n",
    "    \n",
    "    data2 = data.loc[data.Day_num >= day_start]\n",
    "\n",
    "    # Set the dataframe where we will update the predictions\n",
    "    data_pred = data[data.ForecastId != -1][['Country_Region', 'Province_State', 'Day_num', 'ForecastId']]\n",
    "    data_pred = data_pred.loc[data_pred['Day_num']>=day_start]\n",
    "    data_pred['Predicted_ConfirmedCases'] = [0]*len(data_pred)\n",
    "    data_pred['Predicted_Fatalities'] = [0]*len(data_pred)\n",
    "\n",
    "    print(\"Currently running Logistic Regression for all countries\")\n",
    "\n",
    "    # Main loop for countries\n",
    "    for c in data2['Country_Region'].unique():\n",
    "\n",
    "        # List of provinces\n",
    "        provinces_list = data2[data2['Country_Region']==c]['Province_State'].unique()\n",
    "\n",
    "        # If the country has several Province/State informed\n",
    "        if len(provinces_list)>1:\n",
    "            for p in provinces_list:\n",
    "                data_cp = data2[(data2['Country_Region']==c) & (data2['Province_State']==p)]\n",
    "                X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n",
    "                model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n",
    "                model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n",
    "                data_pred.loc[((data_pred['Country_Region']==c) & (data2['Province_State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n",
    "                data_pred.loc[((data_pred['Country_Region']==c) & (data2['Province_State']==p)), 'Predicted_Fatalities'] = pred_2\n",
    "\n",
    "        # No Province/State informed\n",
    "        else:\n",
    "            data_c = data2[(data2['Country_Region']==c)]\n",
    "            X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n",
    "            model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n",
    "            model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n",
    "            data_pred.loc[(data_pred['Country_Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n",
    "            data_pred.loc[(data_pred['Country_Region']==c), 'Predicted_Fatalities'] = pred_2\n",
    "\n",
    "    # Apply exponential transf. and clean potential infinites due to final numerical precision\n",
    "    data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.expm1(x))\n",
    "    data_pred.replace([np.inf, -np.inf], 0, inplace=True) \n",
    "    \n",
    "    return data_pred\n",
    "\n",
    "\n",
    "day_start = 45\n",
    "data_pred = linreg_basic_all_countries(data, day_start)\n",
    "get_submission(data_pred, 'Predicted_ConfirmedCases', 'Predicted_Fatalities')\n",
    "\n",
    "print(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def timeseries_train_test_split(X, y, test_size):\n",
    "#     \"\"\"\n",
    "#         Perform train-test split with respect to time series structure\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # get the index after which test set starts\n",
    "#     test_index = int(len(X)*(1-test_size))\n",
    "    \n",
    "#     X_train = X.iloc[:test_index]\n",
    "#     y_train = y.iloc[:test_index]\n",
    "#     X_test = X.iloc[test_index:]\n",
    "#     y_test = y.iloc[test_index:]\n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# def timeseriesCVscore(model, X, y, n_splits, loss_function):\n",
    "#     \"\"\"\n",
    "#         Returns error on CV  \n",
    "        \n",
    "#         params - vector of parameters for optimization\n",
    "#         series - dataset with timeseries\n",
    "#         slen - season length for Holt-Winters model\n",
    "#     \"\"\"\n",
    "#     # errors array\n",
    "#     errors = []\n",
    "\n",
    "    \n",
    "#     # set the number of folds for cross-validation\n",
    "#     tscv = TimeSeriesSplit(n_splits=n_splits) \n",
    "    \n",
    "#     # iterating over folds, train model on each, forecast and calculate error\n",
    "#     for train, test in tscv.split(X, y):\n",
    "#         start_time = time.time()\n",
    "#         model = model.fit(X[train], y[train])\n",
    "#         fit_time = time.time() - start_time\n",
    "        \n",
    "#         y_pred = model.predict(X[test])\n",
    "#         y_true = y[test]\n",
    "#         error = loss_function(y_pred, y_true)\n",
    "#         score_time = time.time() - start_time - fit_time\n",
    "#         errors.append(error)\n",
    "        \n",
    "#         cv_results['train_score'].append()\n",
    "#         cv_results['test_score'].append(error)\n",
    "    \n",
    "#     res\n",
    "#     return np.mean(np.array(errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
